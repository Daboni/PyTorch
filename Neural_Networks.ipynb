{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Networks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S3eVtXo1Xiu",
        "outputId": "e4813886-0e7a-4086-ecf3-a2b799902f5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    #입력 이미지 채널 1개, 출력 채널 6개, 3X3의 정사각 컨볼루션 행렬\n",
        "    #컨볼루션 커널 정의\n",
        "    self.conv1 = nn.Conv2d(1,6,3)\n",
        "    self.conv2 = nn.Conv2d(6,16,3)\n",
        "    #아핀 (affine) 연산 : y = Wx + b\n",
        "    self.fc1 = nn.Linear(16*6*6, 120) #6*6은 이미지 차원\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  \n",
        "  def forward(self,x):\n",
        "    #(2,2) 크기의 윈도우에 대해 맥스 풀링(max pooling)\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
        "    #크기가 제곱수라면 하나의 숫자만을 특정\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
        "    x= x.view(-1,self.num_flat_feature(x))\n",
        "    x= F.relu(self.fc1(x))\n",
        "    x= F.relu(self.fc2(x))\n",
        "    x= self.fc3(x)\n",
        "    return x\n",
        "  \n",
        "  def num_flat_feature(self,x):\n",
        "    size = x.size()[1:] # 배치 차원을 제외한 모든 차원\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Qu7ueY6xcQ"
      },
      "source": [
        "모델의 학습 가능한 매개변수들은 net.parameters()에 의해 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kELmEueh5njk",
        "outputId": "7b67635a-b05f-4f19-d35e-68274e469dd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkhtzqHt7FO6",
        "outputId": "fb5afff0-9244-4582-b578-36c08526d81d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(params[1].size())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijV2yVb47KCp",
        "outputId": "b86286e0-428b-4798-ab07-7f72d25ecb0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input  = torch.randn(1,1,32,32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0619, -0.1187,  0.0085, -0.0201,  0.0772, -0.0558,  0.0628, -0.0540,\n",
            "          0.0967, -0.1138]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZNKwJpE8MPM"
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1,10))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs3l4Q9J8k5P"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNusqLTW9DAg"
      },
      "source": [
        "손실 함수(Loss Function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cusgqoPY9Fkp",
        "outputId": "ff0ff9c5-9be1-4e7e-fb89-6a341caf8a14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)\n",
        "target = target.view(1,-1)\n",
        "criterion = nn.MSELoss() #평균제곱오차\n",
        "\n",
        "loss = criterion(output,target)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.4665, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG4_hSQY_Ppt",
        "outputId": "923fefb3-81bf-428f-e79e-a99a77b7c2fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "target = torch.randn(10)\n",
        "print(target)\n",
        "target = target.view(1,-1)\n",
        "print(target)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.9231, -0.3744, -0.8557,  0.1418,  0.1753, -1.1366,  0.5112, -0.6396,\n",
            "         0.1711,  1.5355])\n",
            "tensor([[-0.9231, -0.3744, -0.8557,  0.1418,  0.1753, -1.1366,  0.5112, -0.6396,\n",
            "          0.1711,  1.5355]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxiyHBOy_dEc"
      },
      "source": [
        "역전파(Backpropagation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECWZk6NhBYx1"
      },
      "source": [
        "변화도 누적을 피하기 위해 변화도 버퍼를 수동으로 0으로 설정이 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPMTBV2X_V3g",
        "outputId": "f748ad43-7f79-42a5-ee58-ccd103a48e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "net.zero_grad() #모든 매개변수의 변화도를 0으로 초기화\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([ 0.0012,  0.0048,  0.0057, -0.0092,  0.0051, -0.0047])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTaeQl9cANKK"
      },
      "source": [
        "가중치 갱신"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBdl7AdpARkX"
      },
      "source": [
        "확률적 경사 하강법(SGD;Stochaastic Grdient Descent) : 새로운 가중치 = 가중치 - 학습률 * 변화도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS-z2gHCAHE-",
        "outputId": "d1722302-4bbe-41e0-df43-c847aa0b3ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "  f.data.sub_(f.grad.data*learning_rate)\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "ouput = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d0a3f5e1a064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXY56DbeEdp5",
        "outputId": "33821c20-12ea-475b-8067-6d2f666b4e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AccumulateGrad object at 0x7f90ab0947f0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZcKINkSHoOx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}